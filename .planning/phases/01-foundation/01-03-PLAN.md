---
phase: 01-foundation
plan: 03
type: tdd
wave: 3
depends_on:
  - "01-01"
  - "01-02"
files_modified:
  - lobster/core/vector/config.py
  - lobster/core/vector/service.py
  - lobster/core/vector/__init__.py
  - tests/unit/core/vector/__init__.py
  - tests/unit/core/vector/test_vector_search_service.py
  - tests/unit/core/vector/test_config.py
  - tests/unit/core/vector/test_schemas.py
autonomous: true
requirements:
  - INFRA-01
  - INFRA-02

must_haves:
  truths:
    - "VectorSearchService.query('heart attack', 'mondo_v2024_01') returns a list of OntologyMatch dicts with term, ontology_id, score (0-1 cosine similarity), metadata, distance_metric fields"
    - "VectorSearchService.query_batch(['heart attack', 'lung cancer'], 'mondo_v2024_01') returns a list of lists of match dicts"
    - "VectorSearchConfig.from_env() reads LOBSTER_VECTOR_BACKEND, LOBSTER_EMBEDDING_PROVIDER, LOBSTER_VECTOR_STORE_PATH environment variables"
    - "VectorSearchConfig.create_backend() returns a ChromaDBBackend instance and create_embedder() returns a SapBERTEmbedder instance (for default config)"
    - "ChromaDB cosine distances are converted to similarity scores (score = 1.0 - distance, clamped to [0,1]) in _format_results"
    - "Default top_k is 5 per user decision"
    - "All unit tests pass with mock embedder and ephemeral ChromaDB backend (no real SapBERT model needed)"
  artifacts:
    - path: "lobster/core/vector/config.py"
      provides: "VectorSearchConfig with env var reading and factory methods"
      contains: "class VectorSearchConfig"
    - path: "lobster/core/vector/service.py"
      provides: "VectorSearchService with query(), query_batch(), _format_results()"
      contains: "class VectorSearchService"
    - path: "tests/unit/core/vector/test_vector_search_service.py"
      provides: "Unit tests for VectorSearchService with mock embedder and ephemeral backend"
      contains: "def test_query_returns_ontology_matches"
    - path: "tests/unit/core/vector/test_config.py"
      provides: "Unit tests for VectorSearchConfig env var reading and factory methods"
      contains: "def test_from_env_defaults"
    - path: "tests/unit/core/vector/test_schemas.py"
      provides: "Unit tests for Pydantic schemas and enum validation"
      contains: "def test_ontology_match_creation"
  key_links:
    - from: "lobster/core/vector/service.py"
      to: "lobster/core/vector/backends/base.py"
      via: "VectorSearchService._get_backend() returns BaseVectorBackend"
      pattern: "_get_backend.*BaseVectorBackend"
    - from: "lobster/core/vector/service.py"
      to: "lobster/core/vector/embeddings/base.py"
      via: "VectorSearchService._get_embedder() returns BaseEmbedder"
      pattern: "_get_embedder.*BaseEmbedder"
    - from: "lobster/core/vector/config.py"
      to: "lobster/core/vector/backends/chromadb_backend.py"
      via: "create_backend() factory imports and instantiates ChromaDBBackend"
      pattern: "create_backend"
    - from: "lobster/core/vector/config.py"
      to: "lobster/core/vector/embeddings/sapbert.py"
      via: "create_embedder() factory imports and instantiates SapBERTEmbedder"
      pattern: "create_embedder"
    - from: "lobster/core/vector/__init__.py"
      to: "lobster/core/vector/service.py"
      via: "re-exports VectorSearchService and VectorSearchConfig"
      pattern: "VectorSearchService|VectorSearchConfig"
---

<objective>
Implement VectorSearchConfig (env var reading + factory methods) and VectorSearchService (orchestrator: embed -> search -> format results) with comprehensive TDD tests using mock embedder and ephemeral ChromaDB.

Purpose: This is the user-facing API that agents will call. The service orchestrates the full query flow: get embedder -> embed query -> search backend -> convert distances to scores -> return flat match dicts. Config provides env-var-driven creation of backend and embedder instances.

Output: Config class, service class, updated __init__.py re-exports, and 3 test files covering schemas, config, and service behavior.
</objective>

<execution_context>
@/Users/tyo/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tyo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@lobster/core/vector/backends/base.py
@lobster/core/vector/embeddings/base.py
@lobster/core/schemas/search.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create VectorSearchConfig and VectorSearchService</name>
  <files>
    lobster/core/vector/config.py
    lobster/core/vector/service.py
    lobster/core/vector/__init__.py
  </files>
  <action>
**`lobster/core/vector/config.py` — VectorSearchConfig:**

Pydantic v2 BaseModel with:
- `backend: SearchBackend` — default `SearchBackend.CHROMADB`
- `embedding_provider: EmbeddingProvider` — default `EmbeddingProvider.SAPBERT`
- `persist_path: str` — default empty string (resolved in from_env)
- `default_top_k: int` — default `5` (per user decision: "Return top 5 results by default")

Class methods:
- `from_env(cls) -> VectorSearchConfig`: Read env vars:
  - `LOBSTER_VECTOR_BACKEND` -> backend (default "chromadb")
  - `LOBSTER_EMBEDDING_PROVIDER` -> embedding_provider (default "sapbert")
  - `LOBSTER_VECTOR_STORE_PATH` -> persist_path (default `~/.lobster/vector_store/`)

Factory methods (lazy imports inside each):
- `create_backend(self) -> BaseVectorBackend`:
  - If `self.backend == SearchBackend.CHROMADB`: import and return `ChromaDBBackend(persist_path=self.persist_path)`
  - Else: raise `ValueError(f"Unsupported backend: {self.backend}. Available: chromadb")`
- `create_embedder(self) -> BaseEmbedder`:
  - If `self.embedding_provider == EmbeddingProvider.SAPBERT`: import and return `SapBERTEmbedder()`
  - Else: raise `ValueError(f"Unsupported embedding provider: {self.embedding_provider}. Available: sapbert")`

Import `SearchBackend`, `EmbeddingProvider` from `lobster.core.schemas.search`. Import base ABCs for type hints (use TYPE_CHECKING guard).

**`lobster/core/vector/service.py` — VectorSearchService:**

Constructor:
- `__init__(self, config: VectorSearchConfig | None = None, backend: BaseVectorBackend | None = None, embedder: BaseEmbedder | None = None)`:
  - Store config (default: `VectorSearchConfig.from_env()`)
  - Allow direct injection of backend/embedder for testing (if provided, skip factory)
  - `self._backend = backend` (None = lazy via config factory)
  - `self._embedder = embedder` (None = lazy via config factory)

Lazy getters:
- `_get_backend(self) -> BaseVectorBackend`: if None, call `self._config.create_backend()`
- `_get_embedder(self) -> BaseEmbedder`: if None, call `self._config.create_embedder()`

Public methods (per user decisions):
- `query(self, text: str, collection: str, top_k: int | None = None) -> list[dict]`:
  - `top_k = top_k or self._config.default_top_k`
  - Embed: `query_embedding = self._get_embedder().embed_text(text)`
  - Search: `raw_results = self._get_backend().search(collection, query_embedding, n_results=top_k)`
  - Format: `return self._format_results(raw_results, query_text=text)`

- `query_batch(self, texts: list[str], collection: str, top_k: int | None = None) -> list[list[dict]]`:
  - `top_k = top_k or self._config.default_top_k`
  - Batch embed: `embeddings = self._get_embedder().embed_batch(texts)`
  - For each (text, embedding) pair: search + format
  - Return list of match lists

- `_format_results(self, raw: dict, query_text: str) -> list[dict]`:
  - Convert ChromaDB column-oriented results to flat match dicts
  - CRITICAL: Convert cosine distance to similarity: `score = max(0.0, min(1.0, 1.0 - distance))`
  - Round score to 4 decimal places
  - Each match dict: `{"term": ..., "ontology_id": ..., "score": ..., "metadata": ..., "distance_metric": "cosine"}`
  - Handle empty results gracefully (return [])
  - Per research Pattern 3 and user decisions

**Update `lobster/core/vector/__init__.py`:**
- Add lazy imports for `VectorSearchService` and `VectorSearchConfig` that only import when accessed
- Use a pattern like:
  ```python
  def __getattr__(name):
      if name == "VectorSearchService":
          from lobster.core.vector.service import VectorSearchService
          return VectorSearchService
      if name == "VectorSearchConfig":
          from lobster.core.vector.config import VectorSearchConfig
          return VectorSearchConfig
      ...
      raise AttributeError(f"module {__name__!r} has no attribute {name!r}")
  ```
- This ensures `from lobster.core.vector import VectorSearchService` works but does not import heavy deps until the class is actually used.

CRITICAL: The service accepts injected backend/embedder for testability. Tests will use mock embedder + real ephemeral ChromaDB or mock backend.
  </action>
  <verify>
`cd /Users/tyo/omics-os/lobster && python -c "
import sys, os
pre = set(sys.modules.keys())
from lobster.core.vector import VectorSearchService, VectorSearchConfig
post = set(sys.modules.keys())
new = post - pre
has_heavy = any(m in new for m in ['torch', 'sentence_transformers', 'chromadb'])
print('Lazy import OK, heavy deps loaded:', has_heavy)

# Test config from env
os.environ.pop('LOBSTER_VECTOR_BACKEND', None)
os.environ.pop('LOBSTER_EMBEDDING_PROVIDER', None)
config = VectorSearchConfig.from_env()
print('Config backend:', config.backend)
print('Config embedder:', config.embedding_provider)
print('Config top_k:', config.default_top_k)
"`
  </verify>
  <done>VectorSearchConfig reads env vars and provides create_backend/create_embedder factories. VectorSearchService.query() and query_batch() orchestrate embed->search->format flow. Lazy loading preserved. Default top_k is 5.</done>
</task>

<task type="auto">
  <name>Task 2: Write comprehensive TDD test suite for schemas, config, and service</name>
  <files>
    tests/unit/core/vector/__init__.py
    tests/unit/core/vector/test_schemas.py
    tests/unit/core/vector/test_config.py
    tests/unit/core/vector/test_vector_search_service.py
  </files>
  <action>
Create test directory and 3 test files. Use TDD approach: tests define expected behavior, implementation (Task 1) makes them pass.

**Test fixtures (shared via conftest or inline):**

Mock embedder:
```python
class MockEmbedder(BaseEmbedder):
    """Deterministic mock embedder for unit tests -- no torch required."""
    DIMENSIONS = 768

    def embed_text(self, text: str) -> list[float]:
        import hashlib
        h = hashlib.md5(text.encode()).hexdigest()
        return [int(c, 16) / 15.0 for c in h] * 48  # 768 dims

    def embed_batch(self, texts: list[str]) -> list[list[float]]:
        return [self.embed_text(t) for t in texts]

    @property
    def dimensions(self) -> int:
        return self.DIMENSIONS
```

Mock backend (for pure unit tests without chromadb):
```python
class MockVectorBackend(BaseVectorBackend):
    """In-memory mock backend for unit tests."""
    def __init__(self):
        self._collections: dict[str, list] = {}
    # implement add_documents, search (return column-oriented format), delete, count
```

**`tests/unit/core/vector/test_schemas.py`:**
- `test_ontology_match_creation`: Create OntologyMatch with all fields, verify model_dump()
- `test_ontology_match_defaults`: Create with only required fields, verify defaults (metadata={}, distance_metric="cosine")
- `test_ontology_match_score_bounds`: Verify score field accepts 0.0, 1.0, rejects <0 and >1 (use Pydantic ge/le validators if set, or test whatever validation exists)
- `test_search_result_creation`: Create SearchResult with query, collection, matches list, top_k
- `test_search_response_creation`: Create SearchResponse with results, backend, embedding_provider
- `test_search_backend_enum_values`: Verify all 3 members: chromadb, faiss, pgvector
- `test_embedding_provider_enum_values`: Verify all 3 members: sapbert, minilm, openai
- `test_reranker_type_enum_values`: Verify all 3 members: cross_encoder, cohere, none
- `test_literature_match_creation`: Create LiteratureMatch, verify fields

**`tests/unit/core/vector/test_config.py`:**
- `test_from_env_defaults`: VectorSearchConfig.from_env() with no env vars -> chromadb backend, sapbert embedder, default path
- `test_from_env_custom_backend`: Set LOBSTER_VECTOR_BACKEND=faiss -> config.backend == SearchBackend.FAISS
- `test_from_env_custom_path`: Set LOBSTER_VECTOR_STORE_PATH=/tmp/custom -> config.persist_path == /tmp/custom
- `test_create_backend_chromadb`: config.create_backend() returns ChromaDBBackend (mock or skip if chromadb not installed)
- `test_create_embedder_sapbert`: config.create_embedder() returns SapBERTEmbedder (skip if sentence-transformers not installed -- the import guard will fire)
- `test_create_backend_unsupported`: config with backend=faiss -> create_backend() raises ValueError
- `test_default_top_k_is_5`: config.default_top_k == 5

**`tests/unit/core/vector/test_vector_search_service.py`:**
- `test_query_returns_list_of_dicts`: Use MockEmbedder + MockVectorBackend. query("heart attack", "mondo") returns list of dicts
- `test_query_result_shape`: Each dict has keys: term, ontology_id, score, metadata, distance_metric
- `test_query_distance_to_similarity_conversion`: Mock backend returns distances [0.1, 0.3, 0.8]. Verify scores are [0.9, 0.7, 0.2] (1 - distance)
- `test_query_score_clamped_0_1`: Mock backend returns distance -0.1 and 1.5. Verify scores clamped to [0, 1]
- `test_query_default_top_k_5`: query without top_k uses 5
- `test_query_custom_top_k`: query with top_k=10 passes 10 to backend
- `test_query_batch_returns_list_of_lists`: query_batch(["a", "b"], "mondo") returns 2 lists
- `test_query_empty_collection`: Mock backend returns empty results. Verify query returns []
- `test_distance_metric_in_results`: Every match dict has distance_metric="cosine"
- `test_service_accepts_injected_backend_and_embedder`: Construct VectorSearchService(backend=mock, embedder=mock), verify no factory calls
- `test_service_lazy_initialization`: Construct VectorSearchService(), verify _backend and _embedder are None before first query

Use `pytest.mark.skipif` for tests that need chromadb/sentence-transformers. Pure mock tests should run everywhere.

**`tests/unit/core/vector/__init__.py`:** Empty file.
  </action>
  <verify>
Run tests:
`cd /Users/tyo/omics-os/lobster && python -m pytest tests/unit/core/vector/ -v --tb=short 2>&1 | tail -30`

Expected: All tests pass (tests using real chromadb/sentence-transformers may be skipped if not installed, but all mock-based tests pass).
  </verify>
  <done>All unit tests pass. test_schemas.py validates all Pydantic models and enums. test_config.py validates env var reading and factory methods. test_vector_search_service.py validates query/query_batch behavior, distance-to-similarity conversion, score clamping, default top_k=5, and injection.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/unit/core/vector/ -v` -- all tests pass
2. `from lobster.core.vector import VectorSearchService, VectorSearchConfig` works without loading heavy deps
3. VectorSearchService with mock embedder + mock backend: query("test", "collection") returns list of match dicts
4. Distance-to-similarity conversion: distance 0.1 -> score 0.9
5. Default top_k is 5
6. Config env var reading works for LOBSTER_VECTOR_BACKEND, LOBSTER_EMBEDDING_PROVIDER, LOBSTER_VECTOR_STORE_PATH
</verification>

<success_criteria>
- VectorSearchConfig.from_env() reads 3 env vars with correct defaults
- VectorSearchConfig.create_backend() and create_embedder() return correct implementations
- VectorSearchService.query() returns flat match dicts with term, ontology_id, score, metadata, distance_metric
- VectorSearchService.query_batch() returns list of match lists
- ChromaDB cosine distances correctly converted to similarity scores (0-1)
- Default top_k is 5
- All tests pass with mock embedder (no real SapBERT model needed for unit tests)
- Lazy loading preserved: importing VectorSearchService does not load torch/chromadb
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
