---
phase: 02-transcriptomics-parent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/lobster-transcriptomics/lobster/services/analysis/enhanced_singlecell_service.py
  - packages/lobster-transcriptomics/lobster/services/analysis/bulk_preprocessing_service.py
  - packages/lobster-transcriptomics/tests/services/analysis/test_enhanced_singlecell_service.py
  - packages/lobster-transcriptomics/tests/services/analysis/test_bulk_preprocessing_service.py
autonomous: true
requirements: [SCT-02, SCT-03, BLK-03, BLK-04, BLK-05, BLK-06]

must_haves:
  truths:
    - "integrate_batches returns AnnData with X_pca_harmony in obsm, plus batch_silhouette and median_lisi in stats"
    - "compute_trajectory returns AnnData with dpt_pseudotime in obs and paga connectivity in uns"
    - "BulkPreprocessingService has 4 methods that each return (AnnData, Dict, AnalysisStep) 3-tuple"
    - "Harmony import is lazy with HARMONY_AVAILABLE flag (matching scrublet pattern)"
  artifacts:
    - path: "packages/lobster-transcriptomics/lobster/services/analysis/enhanced_singlecell_service.py"
      provides: "integrate_batches and compute_trajectory methods"
      contains: "def integrate_batches"
    - path: "packages/lobster-transcriptomics/lobster/services/analysis/bulk_preprocessing_service.py"
      provides: "Bulk QC, filtering, normalization, batch detection"
      contains: "class BulkPreprocessingService"
    - path: "packages/lobster-transcriptomics/tests/services/analysis/test_bulk_preprocessing_service.py"
      provides: "Tests for all 4 BulkPreprocessingService methods"
      contains: "test_assess_sample_quality"
  key_links:
    - from: "enhanced_singlecell_service.py"
      to: "scanpy.external.pp.harmony_integrate"
      via: "lazy import with HARMONY_AVAILABLE guard"
      pattern: "HARMONY_AVAILABLE"
    - from: "enhanced_singlecell_service.py"
      to: "scanpy.tl.dpt"
      via: "direct scanpy call with auto root cell selection"
      pattern: "sc\\.tl\\.dpt"
    - from: "bulk_preprocessing_service.py"
      to: "pydeseq2"
      via: "DeseqDataSet for size factors and VST"
      pattern: "DeseqDataSet"
---

<objective>
Add new service methods for single-cell batch integration, trajectory inference, and bulk RNA-seq preprocessing.

Purpose: These service methods provide the 3-tuple returns that Plan 02 (SC tools) and Plan 03 (bulk tools) will wrap as @tool functions. Services first, tools second — matching the Phase 1 pattern.

Output: 2 new methods on EnhancedSingleCellService (integrate_batches, compute_trajectory) + 1 new BulkPreprocessingService class with 4 methods (assess_sample_quality, filter_genes, normalize_counts, detect_batch_effects) + tests.
</objective>

<execution_context>
@/Users/tyo/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tyo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcriptomics-parent/02-RESEARCH.md

# Key source files
@packages/lobster-transcriptomics/lobster/services/analysis/enhanced_singlecell_service.py
@packages/lobster-transcriptomics/pyproject.toml
@lobster/services/analysis/bulk_rnaseq_service.py

# Phase 1 service pattern reference
@.planning/phases/01-genomics-domain/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add integrate_batches and compute_trajectory to EnhancedSingleCellService</name>
  <files>
    packages/lobster-transcriptomics/lobster/services/analysis/enhanced_singlecell_service.py
    packages/lobster-transcriptomics/tests/services/analysis/test_enhanced_singlecell_service.py
  </files>
  <action>
Add two new methods to `EnhancedSingleCellService`:

**1. `integrate_batches` method** (SCT-02):
- Signature: `def integrate_batches(self, adata, batch_key, method="harmony", n_pcs=30, max_iter=20) -> Tuple[AnnData, Dict, AnalysisStep]`
- Copy adata first (`adata = adata.copy()`)
- Ensure PCA is computed: if "X_pca" not in adata.obsm, run `sc.tl.pca(adata, n_comps=n_pcs)`
- If method == "harmony": use `sc.external.pp.harmony_integrate(adata, key=batch_key, basis="X_pca", adjusted_basis="X_pca_harmony", max_iter_harmony=max_iter)`. Guard with `HARMONY_AVAILABLE` flag.
- If method == "combat": use `sc.pp.combat(adata, key=batch_key)` then rerun PCA. integrated_key = "X_pca".
- Compute quality metrics after integration:
  - Batch silhouette score: `sklearn.metrics.silhouette_score(X_integrated, batch_labels)` — lower means better mixing
  - LISI: implement `_compute_lisi(X, labels, k=30)` as a private method using sklearn NearestNeighbors. For each cell, get k neighbors, compute inverse Simpson index on batch label distribution. Validate smallest batch >= k+1 cells, reduce k if needed.
- Stats dict must include: method, batch_key, n_batches, batch_silhouette (float), median_lisi (float), integrated_key
- Build AnalysisStep IR with code_template for harmony_integrate, imports for scanpy
- **Lazy import pattern** (matching scrublet at top of file): Add `try: import harmonypy; HARMONY_AVAILABLE = True except ImportError: HARMONY_AVAILABLE = False` near the existing scrublet import block. Check `HARMONY_AVAILABLE` before calling harmony_integrate, raise clear error with install instructions if missing.

**2. `compute_trajectory` method** (SCT-03):
- Signature: `def compute_trajectory(self, adata, root_cell=None, root_group=None, cluster_key="leiden", n_dcs=15, method="dpt") -> Tuple[AnnData, Dict, AnalysisStep]`
- Copy adata first
- Ensure neighbors computed: if "neighbors" not in adata.uns, run `sc.pp.neighbors(adata)`
- Compute diffusion map: `sc.tl.diffmap(adata, n_comps=n_dcs)`
- Set root cell: (a) explicit root_cell index, (b) root_group: find cell in cluster closest to DC1 extreme, (c) auto: cell at minimum of DC1
- Compute DPT: `sc.tl.dpt(adata)`
- Always compute PAGA: `sc.tl.paga(adata, groups=cluster_key)`
- Stats: method, n_dcs, root_cell_index, pseudotime_range [min, max], has_paga
- Build AnalysisStep IR with code_template

**Tests:** Add to existing test_enhanced_singlecell_service.py:
- `test_integrate_batches_harmony`: Create small AnnData with batch column, mock harmony if not installed, verify X_pca_harmony in obsm, verify stats keys
- `test_integrate_batches_combat`: Test combat path, verify 3-tuple return
- `test_integrate_batches_no_harmony`: Verify clear error when harmony not available
- `test_compute_trajectory`: Create AnnData with PCA+neighbors, verify dpt_pseudotime in obs, paga in uns
- `test_compute_trajectory_root_group`: Verify root_group selection logic
  </action>
  <verify>
Run: `cd /Users/tyo/Omics-OS/lobster && python -c "from lobster.services.analysis.enhanced_singlecell_service import EnhancedSingleCellService; s = EnhancedSingleCellService(); print('integrate_batches' in dir(s) and 'compute_trajectory' in dir(s))"`
Expected: `True`

Run: `cd /Users/tyo/Omics-OS/lobster && python -m pytest packages/lobster-transcriptomics/tests/services/analysis/test_enhanced_singlecell_service.py -v -x --tb=short 2>&1 | tail -20`
  </verify>
  <done>
EnhancedSingleCellService has integrate_batches (with Harmony/Combat + LISI/silhouette metrics) and compute_trajectory (DPT/PAGA with auto root selection). Both return proper 3-tuples with AnalysisStep IR. Tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create BulkPreprocessingService with 4 methods</name>
  <files>
    packages/lobster-transcriptomics/lobster/services/analysis/bulk_preprocessing_service.py
    packages/lobster-transcriptomics/tests/services/analysis/test_bulk_preprocessing_service.py
  </files>
  <action>
Create a NEW file `packages/lobster-transcriptomics/lobster/services/analysis/bulk_preprocessing_service.py` with a `BulkPreprocessingService` class. This service is stateless (no constructor args) and handles bulk RNA-seq preprocessing steps. All methods return the 3-tuple `(AnnData, Dict, AnalysisStep)`.

**Class: BulkPreprocessingService**

**1. `assess_sample_quality` method** (BLK-03):
- Signature: `def assess_sample_quality(self, adata, batch_key=None) -> Tuple[AnnData, Dict, AnalysisStep]`
- Compute log-CPM: `np.log1p(adata.X / adata.X.sum(axis=1, keepdims=True) * 1e6)` (handle sparse)
- Run PCA on log-CPM (use sklearn PCA, not scanpy — this is sample-level PCA, not gene-level)
- Flag outlier samples: compute distance from centroid, flag >3 SD
- Compute pairwise Pearson correlation matrix between samples
- If batch_key provided: compute R-squared of batch vs PC1-3 to quantify batch effect magnitude
- Store results in adata.obs ("is_outlier", "distance_from_centroid") and adata.uns ("sample_correlation_matrix", "batch_r_squared")
- Stats: n_samples, n_outliers, outlier_names, median_correlation, batch_r_squared (if applicable)
- Build IR with code_template

**2. `filter_genes` method** (BLK-04):
- Signature: `def filter_genes(self, adata, min_counts=10, min_samples=3) -> Tuple[AnnData, Dict, AnalysisStep]`
- Filter genes where total counts < min_counts across all samples
- Filter genes expressed in fewer than min_samples samples (expression = count > 0)
- This is different from SC filtering (which filters by cells-per-gene percentage)
- Stats: n_genes_before, n_genes_after, n_filtered, filter_criteria
- Build IR

**3. `normalize_counts` method** (BLK-05):
- Signature: `def normalize_counts(self, adata, method="deseq2", target_sum=None) -> Tuple[AnnData, Dict, AnalysisStep]`
- method="deseq2": Use pyDESeq2 `DeseqDataSet` to compute size factors. Store raw counts in `adata.layers["counts"]`, normalized in `adata.X`. Import pyDESeq2 lazily.
- method="vst": Variance-stabilizing transform via pyDESeq2. Store VST values in `adata.X` and raw in `adata.layers["counts"]`.
- method="cpm": Simple counts-per-million: `X / library_size * 1e6`. Store raw in layers["counts"].
- Stats: method, mean_size_factor (for deseq2), library_size_range (for cpm)
- Build IR

**4. `detect_batch_effects` method** (BLK-06):
- Signature: `def detect_batch_effects(self, adata, batch_key, condition_key=None) -> Tuple[AnnData, Dict, AnalysisStep]`
- Compute PCA if not done
- For each PC (1-5): compute variance explained by batch_key and condition_key (if provided) using simple OLS (numpy lstsq or scipy)
- Compute overall batch variance proportion
- Store results in adata.uns["batch_effects"]
- Recommend correction if batch variance > condition variance on top PCs
- Stats: batch_variance_pcs, condition_variance_pcs (if applicable), recommendation (str)
- Build IR

**Tests:** Create `test_bulk_preprocessing_service.py`:
- `test_assess_sample_quality`: Create AnnData (20 samples x 1000 genes), verify outlier detection, correlation matrix
- `test_assess_sample_quality_with_batch`: Add batch column, verify R-squared computed
- `test_filter_genes`: Create AnnData, add some low-count genes, verify filtering
- `test_normalize_counts_deseq2`: Verify size factors computed (mock pyDESeq2 if needed)
- `test_normalize_counts_cpm`: Verify CPM normalization, raw counts preserved in layers
- `test_detect_batch_effects`: Create data with known batch effect, verify detection
- Each test verifies 3-tuple return shape and AnalysisStep IR presence
  </action>
  <verify>
Run: `cd /Users/tyo/Omics-OS/lobster && python -c "from lobster.services.analysis.bulk_preprocessing_service import BulkPreprocessingService; s = BulkPreprocessingService(); print([m for m in dir(s) if not m.startswith('_')])"`

Run: `cd /Users/tyo/Omics-OS/lobster && python -m pytest packages/lobster-transcriptomics/tests/services/analysis/test_bulk_preprocessing_service.py -v -x --tb=short 2>&1 | tail -20`
  </verify>
  <done>
BulkPreprocessingService exists with 4 methods (assess_sample_quality, filter_genes, normalize_counts, detect_batch_effects). All return 3-tuples with AnalysisStep IR. Tests pass. Service is in the transcriptomics package (not core).
  </done>
</task>

</tasks>

<verification>
1. `python -c "from lobster.services.analysis.enhanced_singlecell_service import EnhancedSingleCellService"` succeeds
2. `python -c "from lobster.services.analysis.bulk_preprocessing_service import BulkPreprocessingService"` succeeds
3. All tests in `packages/lobster-transcriptomics/tests/services/analysis/` pass
4. No changes to core `lobster/` directory — all new code in `packages/lobster-transcriptomics/`
</verification>

<success_criteria>
- EnhancedSingleCellService has integrate_batches (Harmony + Combat) with LISI + silhouette quality metrics
- EnhancedSingleCellService has compute_trajectory (DPT + PAGA) with auto root cell selection
- BulkPreprocessingService has 4 methods covering assess, filter, normalize, batch detect
- All methods return proper 3-tuples with AnalysisStep IR
- harmonypy uses lazy import with HARMONY_AVAILABLE flag (matching scrublet pattern)
- Tests pass for both services
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcriptomics-parent/02-01-SUMMARY.md`
</output>
