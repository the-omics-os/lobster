---
phase: 02-transcriptomics-parent
plan: 03
type: execute
wave: 3
depends_on: [02-01, 02-02]
files_modified:
  - packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py
  - packages/lobster-transcriptomics/lobster/agents/transcriptomics/prompts.py
autonomous: true
requirements: [BLK-01, BLK-02, BLK-03, BLK-04, BLK-05, BLK-06, BLK-07, BLK-08, DOC-02]

must_haves:
  truths:
    - "User can import bulk RNA-seq counts from Salmon/kallisto/featureCounts/CSV via import_bulk_counts tool"
    - "User can merge external sample metadata with a count matrix via merge_sample_metadata tool"
    - "User can assess bulk sample quality (outliers, correlation, batch) via assess_bulk_sample_quality tool"
    - "User can filter lowly-expressed genes via filter_bulk_genes tool"
    - "User can normalize bulk counts (DESeq2/VST/CPM) via normalize_bulk_counts tool"
    - "User can detect batch effects via detect_batch_effects tool"
    - "User can convert gene identifiers (Ensembl/Symbol/Entrez) via convert_gene_identifiers tool"
    - "User can validate data readiness before DE handoff via prepare_bulk_for_de tool"
    - "Prompt routes SC vs bulk workflows with clear decision tree including all new tools"
  artifacts:
    - path: "packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py"
      provides: "8 bulk RNA-seq tools"
      contains: "def import_bulk_counts"
    - path: "packages/lobster-transcriptomics/lobster/agents/transcriptomics/prompts.py"
      provides: "Updated prompt with bulk routing decision tree"
      contains: "Bulk RNA-seq Workflow"
  key_links:
    - from: "transcriptomics_expert.py"
      to: "bulk_preprocessing_service.py"
      via: "assess_sample_quality, filter_genes, normalize_counts, detect_batch_effects"
      pattern: "bulk_preprocessing_service\\."
    - from: "transcriptomics_expert.py"
      to: "bulk_rnaseq_service"
      via: "load_from_quantification_files for Salmon/kallisto import"
      pattern: "bulk_service\\."
    - from: "prompts.py"
      to: "all tool names"
      via: "decision tree referencing exact tool function names"
      pattern: "import_bulk_counts|merge_sample_metadata|filter_bulk_genes"
---

<objective>
Add 8 bulk RNA-seq tools to the transcriptomics expert and update the system prompt to route SC vs bulk workflows with a clear decision tree.

Purpose: This completes the unified transcriptomics parent by adding the full bulk RNA-seq import-to-DE-handoff pipeline. The prompt update ensures the LLM correctly routes between SC tools (~14) and bulk tools (~8) based on data type detection.

Output: 8 new bulk tools in transcriptomics_expert.py + updated prompt in prompts.py covering all SC and bulk tools with routing decision tree.
</objective>

<execution_context>
@/Users/tyo/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tyo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcriptomics-parent/02-RESEARCH.md
@.planning/phases/02-transcriptomics-parent/02-01-SUMMARY.md
@.planning/phases/02-transcriptomics-parent/02-02-SUMMARY.md

# Key source files
@packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py
@packages/lobster-transcriptomics/lobster/agents/transcriptomics/prompts.py
@packages/lobster-transcriptomics/lobster/agents/transcriptomics/config.py
@lobster/services/analysis/bulk_rnaseq_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add 8 bulk RNA-seq tools to transcriptomics_expert</name>
  <files>
    packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py
  </files>
  <action>
Add 8 new @tool functions in a new `# BULK RNA-SEQ TOOLS` section in transcriptomics_expert.py, placed between the SC analysis tools and the "COLLECT ALL TOOLS" section.

**New imports needed at top of file:**
- `from lobster.services.analysis.bulk_rnaseq_service import BulkRNASeqService` (core service for Salmon/kallisto import)
- `from lobster.services.analysis.bulk_preprocessing_service import BulkPreprocessingService` (new service from Plan 01)
- `import pandas as pd`
- `from pathlib import Path`

**New service initialization in factory function (alongside existing services):**
```python
bulk_service = BulkRNASeqService(data_manager=data_manager)
bulk_preprocessing_service = BulkPreprocessingService()
```

**1. import_bulk_counts tool** (BLK-01):
- Signature: `def import_bulk_counts(modality_name: str, file_path: str, source: str = "auto", gene_id_column: str = "auto") -> str`
- Docstring: "Import bulk RNA-seq count data from Salmon, kallisto, featureCounts, or CSV/TSV files."
- If source in ("salmon", "kallisto", "auto") and path is directory: use `bulk_service.load_from_quantification_files(path, tool=source)`
- If source == "featurecounts" or file ends in .txt/.tsv with featureCounts header: parse featureCounts format (skip # comments, drop Chr/Start/End/Strand/Length columns, use Geneid as index)
- If CSV/TSV: read with pandas, create AnnData (samples x genes orientation — transpose if genes > samples)
- Store as modality, log with IR
- Stats: n_samples, n_genes, source detected
- Build a simple AnalysisStep IR for the import operation

**2. merge_sample_metadata tool** (BLK-02):
- Signature: `def merge_sample_metadata(modality_name: str, metadata_file: str, sample_id_column: str = "auto") -> str`
- Docstring: "Join external sample metadata (CSV/TSV/Excel) with count matrix obs."
- Read metadata file (detect format from extension)
- Auto-detect sample ID column: check if any column values overlap with adata.obs_names
- Left-join on sample IDs. Report matched vs unmatched samples.
- Update adata.obs with merged metadata
- Store updated modality, log with IR
- Stats: n_metadata_columns_added, n_samples_matched, n_samples_unmatched

**3. assess_bulk_sample_quality tool** (BLK-03):
- Signature: `def assess_bulk_sample_quality(modality_name: str, batch_key: Optional[str] = None) -> str`
- Wrap `bulk_preprocessing_service.assess_sample_quality(adata, batch_key=batch_key)`
- Store as `{modality_name}_quality_assessed`
- Response: n_outliers, outlier names, median correlation, batch R-squared if applicable, recommendation

**4. filter_bulk_genes tool** (BLK-04):
- Signature: `def filter_bulk_genes(modality_name: str, min_counts: int = 10, min_samples: int = 3) -> str`
- Wrap `bulk_preprocessing_service.filter_genes(adata, min_counts=min_counts, min_samples=min_samples)`
- Store as `{modality_name}_filtered`
- Response: genes before, genes after, genes removed

**5. normalize_bulk_counts tool** (BLK-05):
- Signature: `def normalize_bulk_counts(modality_name: str, method: str = "deseq2") -> str`
- Wrap `bulk_preprocessing_service.normalize_counts(adata, method=method)`
- Store as `{modality_name}_normalized`
- Response: method used, key stats (mean size factor for deseq2, etc.)

**6. detect_batch_effects tool** (BLK-06):
- Signature: `def detect_batch_effects(modality_name: str, batch_key: str, condition_key: Optional[str] = None) -> str`
- Wrap `bulk_preprocessing_service.detect_batch_effects(adata, batch_key=batch_key, condition_key=condition_key)`
- Store as `{modality_name}_batch_assessed`
- Response: variance explained by batch vs condition, recommendation

**7. convert_gene_identifiers tool** (BLK-07):
- Signature: `def convert_gene_identifiers(modality_name: str, source_type: str = "auto", target_type: str = "symbol") -> str`
- Docstring: "Convert gene identifiers between Ensembl, Symbol, and Entrez formats using mygene."
- Lazy import mygene (try/except, provide clear install message if missing)
- Auto-detect source_type: ENSG* = ensembl, digits = entrez, else = symbol
- Use `mygene.MyGeneInfo().querymany(gene_ids, scopes=source_type, fields=target_field, species="human")`
- Strip Ensembl version suffixes before querying (ENSG00000141510.16 -> ENSG00000141510)
- Store original IDs in adata.var["original_id"], set new var_names, make unique
- If mygene not available, fall back to a warning message suggesting pip install
- Store updated modality, log with IR
- Stats: n_converted, n_unmapped, unmapped_gene_names (first 10)

**8. prepare_bulk_for_de tool** (BLK-08):
- Signature: `def prepare_bulk_for_de(modality_name: str, group_key: str, design_factors: Optional[List[str]] = None) -> str`
- Docstring: "Validate that bulk data is ready for differential expression analysis before handoff."
- Checks: (1) raw counts exist (adata.layers["counts"] or adata.X has integer-like values), (2) group_key exists in obs with at least 2 groups, (3) minimum 2 samples per group (warn if <3), (4) design_factors all exist in obs if provided
- Does NOT modify data — purely validation
- Response: pass/fail for each check, overall readiness status, recommendation to handoff_to_de_analysis_expert if ready
- Log with IR

**Update the tool collection section:**
```python
# Bulk RNA-seq tools
bulk_tools = [
    import_bulk_counts,
    merge_sample_metadata,
    assess_bulk_sample_quality,
    filter_bulk_genes,
    normalize_bulk_counts,
    detect_batch_effects,
    convert_gene_identifiers,
    prepare_bulk_for_de,
]

# Combine all direct tools
direct_tools = shared_tools + clustering_tools + sc_analysis_tools + bulk_tools
```
  </action>
  <verify>
Run: `cd /Users/tyo/Omics-OS/lobster && python -c "
import ast
with open('packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py') as f:
    content = f.read()
bulk_tools = ['import_bulk_counts', 'merge_sample_metadata', 'assess_bulk_sample_quality',
              'filter_bulk_genes', 'normalize_bulk_counts', 'detect_batch_effects',
              'convert_gene_identifiers', 'prepare_bulk_for_de']
for name in bulk_tools:
    assert f'def {name}(' in content, f'Missing bulk tool: {name}'
print(f'All {len(bulk_tools)} bulk tools present')
"`

Run: `cd /Users/tyo/Omics-OS/lobster && grep -c "ir=ir" packages/lobster-transcriptomics/lobster/agents/transcriptomics/transcriptomics_expert.py`
Expected: At least 11 (7 SC/clustering tools + 4 bulk tools that use service IR; import/merge/convert/prepare_bulk build their own IR)
  </verify>
  <done>
8 bulk RNA-seq tools added: import_bulk_counts (Salmon/kallisto/featureCounts/CSV), merge_sample_metadata (join metadata), assess_bulk_sample_quality (wraps BulkPreprocessingService), filter_bulk_genes, normalize_bulk_counts, detect_batch_effects, convert_gene_identifiers (mygene with lazy import), prepare_bulk_for_de (validation checkpoint). All tools follow validate→action→store→log→response pattern with ir=ir.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update transcriptomics_expert prompt for SC + bulk routing</name>
  <files>
    packages/lobster-transcriptomics/lobster/agents/transcriptomics/prompts.py
  </files>
  <action>
Rewrite `create_transcriptomics_expert_prompt()` in prompts.py to cover both SC and bulk workflows with a clear decision tree. The prompt must reference the EXACT function names from the code (after renames).

**Structure the prompt with these XML sections:**

1. `<Identity_And_Role>`: Unified transcriptomics expert for SC AND bulk RNA-seq. Mention auto-detection of data type. Core capabilities: SC QC/clustering/annotation, bulk import/QC/normalization, delegation to annotation_expert and de_analysis_expert.

2. `<Data_Type_Detection>`: Keep existing detection logic (obs count, SC columns, sparsity). Add explicit routing rule: "After loading data, classify as SC or BULK. Use SC tools for SC data, bulk tools for bulk data. Some shared tools (check_data_status, assess_data_quality, filter_and_normalize, create_analysis_summary) work for both."

3. `<Your_Tools>`: List ALL tools organized by category:

   **Shared Tools (SC + Bulk):**
   - `check_data_status` — Check data dimensions and type
   - `assess_data_quality` — Calculate QC metrics
   - `filter_and_normalize` — Filter and normalize (auto-detects SC/bulk defaults)
   - `create_analysis_summary` — Generate analysis report
   - `select_variable_features` — Select highly variable genes/features
   - `run_pca` — Principal component analysis
   - `compute_neighbors_and_embed` — Neighbor graph + UMAP embedding

   **Single-Cell Tools:**
   - `detect_doublets` — Scrublet doublet detection (run BEFORE filtering)
   - `integrate_batches` — Harmony/Combat batch integration with quality metrics
   - `compute_trajectory` — DPT pseudotime + PAGA trajectory
   - `cluster_cells` — Leiden clustering + UMAP
   - `subcluster_cells` — Re-cluster specific populations
   - `evaluate_clustering_quality` — Silhouette/DB/CH metrics
   - `find_marker_genes` — Marker genes per cluster

   **Bulk RNA-seq Tools:**
   - `import_bulk_counts` — Import from Salmon/kallisto/featureCounts/CSV
   - `merge_sample_metadata` — Join metadata with count matrix
   - `assess_bulk_sample_quality` — PCA outlier detection, sample correlation
   - `filter_bulk_genes` — Gene filtering (min counts/samples)
   - `normalize_bulk_counts` — DESeq2/VST/CPM normalization
   - `detect_batch_effects` — Variance decomposition for batch effects
   - `convert_gene_identifiers` — Ensembl/Symbol/Entrez conversion
   - `prepare_bulk_for_de` — Validation before DE handoff

   **Delegation Tools:**
   - `handoff_to_annotation_expert` — Cell type annotation (SC only)
   - `handoff_to_de_analysis_expert` — Differential expression (SC pseudobulk or bulk)

4. `<Decision_Tree>`: Clear routing:
   ```
   User request arrives →
   1. Check data type (SC or bulk)
   2. If SC data:
      - QC: detect_doublets → assess_data_quality → filter_and_normalize
      - Multi-sample: integrate_batches (check quality metrics, re-run if needed)
      - Clustering: select_variable_features → run_pca → compute_neighbors_and_embed → cluster_cells
      - Markers: find_marker_genes → handoff_to_annotation_expert
      - Trajectory: compute_trajectory (requires clustering)
      - DE: handoff_to_de_analysis_expert
   3. If bulk data:
      - Import: import_bulk_counts → merge_sample_metadata
      - QC: assess_bulk_sample_quality → filter_bulk_genes
      - Normalize: normalize_bulk_counts (use "deseq2" for DE, "vst" for visualization)
      - Batch: detect_batch_effects → (correct if needed)
      - Gene IDs: convert_gene_identifiers (if Ensembl IDs, convert to symbols)
      - DE ready: prepare_bulk_for_de → handoff_to_de_analysis_expert
   ```

5. `<Standard_Workflows>`: Two subsections:
   - **SC Standard Workflow** (7 steps): detect_doublets → filter_and_normalize → select_variable_features → run_pca → integrate_batches (if multi-sample) → compute_neighbors_and_embed → cluster_cells → find_marker_genes → handoff annotation
   - **Bulk Standard Workflow** (6 steps): import_bulk_counts → merge_sample_metadata → assess_bulk_sample_quality → filter_bulk_genes → normalize_bulk_counts → prepare_bulk_for_de → handoff DE

6. `<Clustering_Guidelines>`: Keep existing resolution guidance. Update tool names to new names (cluster_cells, find_marker_genes).

7. `<Communication_Style>`: Keep existing formatting rules. Add: "For integrate_batches, ALWAYS report LISI and silhouette scores. If batch_silhouette > 0.3 or median_lisi < 1.5, suggest re-running with different parameters."

8. `<Important_Rules>`:
   - ALWAYS call check_data_status() first to understand data type and column names
   - NEVER assume column names (leiden, etc.) — always verify
   - ALWAYS pass ir= to log_tool_usage
   - INVOKE handoff tools immediately when delegation is needed (do NOT just suggest)
   - For bulk data: do NOT use SC-specific tools (cluster_cells, etc.)
   - For SC data: do NOT use bulk-specific tools (import_bulk_counts, etc.)
   - After integrate_batches: use integrated_key for downstream clustering
  </action>
  <verify>
Run: `cd /Users/tyo/Omics-OS/lobster && python -c "
from lobster.agents.transcriptomics.prompts import create_transcriptomics_expert_prompt
prompt = create_transcriptomics_expert_prompt()
# Verify new tool names appear
for name in ['detect_doublets', 'integrate_batches', 'compute_trajectory',
             'import_bulk_counts', 'filter_bulk_genes', 'normalize_bulk_counts',
             'prepare_bulk_for_de', 'cluster_cells', 'find_marker_genes',
             'filter_and_normalize', 'select_variable_features']:
    assert name in prompt, f'Missing from prompt: {name}'
# Verify old names are gone
for old_name in ['cluster_modality', 'find_marker_genes_for_clusters',
                  'filter_and_normalize_modality', 'select_highly_variable_genes']:
    assert old_name not in prompt, f'Old name still in prompt: {old_name}'
print('Prompt validation passed')
print(f'Prompt length: {len(prompt)} chars')
"`
  </verify>
  <done>
Prompt updated with complete SC + bulk tool routing. Decision tree clearly separates SC and bulk workflows. All new tool names (from renames and additions) are referenced. Old tool names removed. Integration quality metrics guidance included.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from lobster.agents.transcriptomics.transcriptomics_expert import transcriptomics_expert"` succeeds (no import errors)
2. All 8 bulk tools have function definitions in transcriptomics_expert.py
3. Prompt references all 22+ tools by correct (new) names
4. No old tool names (cluster_modality, filter_and_normalize_modality, etc.) in prompt
5. `grep -c "ir=ir" transcriptomics_expert.py` shows IR on every tool
6. Prompt has clear SC vs bulk routing decision tree
</verification>

<success_criteria>
- 8 bulk tools wired: import_bulk_counts, merge_sample_metadata, assess_bulk_sample_quality, filter_bulk_genes, normalize_bulk_counts, detect_batch_effects, convert_gene_identifiers, prepare_bulk_for_de
- Prompt updated with all SC + bulk tools, decision tree routing, standard workflows for both data types
- mygene import is lazy with fallback message (matching harmonypy/scrublet pattern)
- prepare_bulk_for_de validates readiness without modifying data
- Total tool count on agent: ~22 direct tools (7 shared + 7 SC/clustering + 8 bulk) + delegation tools
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcriptomics-parent/02-03-SUMMARY.md`
</output>
