---
phase: 05-scalability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lobster/core/vector/backends/faiss_backend.py
  - lobster/core/vector/backends/pgvector_backend.py
  - lobster/core/vector/config.py
  - tests/unit/core/vector/test_backends.py
  - tests/unit/core/vector/test_config.py
autonomous: true
requirements: [INFRA-05, INFRA-06, INFRA-07, TEST-01]

must_haves:
  truths:
    - "VectorSearchConfig(backend=SearchBackend.faiss).create_backend() returns FAISSBackend instance"
    - "VectorSearchConfig(backend=SearchBackend.pgvector).create_backend() returns PgVectorBackend instance"
    - "FAISSBackend.add_documents + search returns correct cosine-compatible distances"
    - "PgVectorBackend raises NotImplementedError with 'v2.0' guidance on all 4 methods"
    - "Service layer distance-to-similarity formula produces correct scores with FAISS distances"
    - "Existing ChromaDB backend and all prior tests still pass unchanged"
  artifacts:
    - path: "lobster/core/vector/backends/faiss_backend.py"
      provides: "FAISS backend implementing BaseVectorBackend with IndexFlatL2, L2 normalization, string-to-int ID mapping, and squared-L2-to-cosine distance conversion"
      contains: "class FAISSBackend"
    - path: "lobster/core/vector/backends/pgvector_backend.py"
      provides: "pgvector stub raising NotImplementedError on all abstract methods"
      contains: "class PgVectorBackend"
    - path: "lobster/core/vector/config.py"
      provides: "Extended create_backend() factory with faiss and pgvector branches"
      contains: "SearchBackend.faiss"
    - path: "tests/unit/core/vector/test_backends.py"
      provides: "Unit tests for FAISS backend (mocked faiss), pgvector stub, and ChromaDB backend contract"
      contains: "class TestFAISSBackend"
    - path: "tests/unit/core/vector/test_config.py"
      provides: "Updated factory tests: faiss creates FAISSBackend, pgvector creates PgVectorBackend"
      contains: "test_create_backend_faiss"
  key_links:
    - from: "lobster/core/vector/config.py"
      to: "lobster/core/vector/backends/faiss_backend.py"
      via: "lazy import in create_backend() factory"
      pattern: "from lobster\\.core\\.vector\\.backends\\.faiss_backend import FAISSBackend"
    - from: "lobster/core/vector/config.py"
      to: "lobster/core/vector/backends/pgvector_backend.py"
      via: "lazy import in create_backend() factory"
      pattern: "from lobster\\.core\\.vector\\.backends\\.pgvector_backend import PgVectorBackend"
    - from: "lobster/core/vector/backends/faiss_backend.py"
      to: "lobster/core/vector/backends/base.py"
      via: "class inheritance"
      pattern: "class FAISSBackend\\(BaseVectorBackend\\)"
    - from: "tests/unit/core/vector/test_backends.py"
      to: "lobster/core/vector/backends/faiss_backend.py"
      via: "import with sys.modules mock for faiss"
      pattern: "patch\\.dict.*sys\\.modules.*faiss"
---

<objective>
Implement FAISS and pgvector backends and wire them into the VectorSearchConfig factory so that setting LOBSTER_VECTOR_BACKEND=faiss switches the entire vector search pipeline with zero code changes at the service layer.

Purpose: Enable backend flexibility for different deployment scenarios -- FAISS for fast in-memory search (no disk I/O), pgvector stub as forward-looking placeholder for v2.0 cloud deployment.

Output: Two new backend modules, updated factory, comprehensive unit tests.
</objective>

<execution_context>
@/Users/tyo/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tyo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-scalability/05-RESEARCH.md

@lobster/core/vector/backends/base.py
@lobster/core/vector/backends/chromadb_backend.py
@lobster/core/vector/config.py
@lobster/core/schemas/search.py
@tests/unit/core/vector/test_config.py
@tests/unit/core/vector/test_embedders.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement FAISS backend, pgvector stub, and factory wiring</name>
  <files>
    lobster/core/vector/backends/faiss_backend.py
    lobster/core/vector/backends/pgvector_backend.py
    lobster/core/vector/config.py
  </files>
  <action>
Create three files/modifications:

**1. `lobster/core/vector/backends/faiss_backend.py`** — FAISSBackend class implementing BaseVectorBackend:

- Import pattern: `from lobster.core.vector.backends.base import BaseVectorBackend` at top; `import faiss` lazily inside `_ensure_faiss()` method (same pattern as ChromaDBBackend._get_client()).
- Use `faiss.IndexIDMap(faiss.IndexFlatL2(dim))` wrapper per collection (not raw IndexFlatL2) so that explicit integer IDs survive deletion without shifting. Research Open Question #2 confirmed this approach.
- Internal state: `self._collections: dict[str, dict]` where each collection value is a dict with keys: `"index"` (IndexIDMap wrapping IndexFlatL2), `"id_to_int"` (str->int mapping), `"int_to_id"` (int->str mapping), `"documents"` (int->str), `"metadatas"` (int->dict), `"next_int_id"` (int counter).

- `_ensure_faiss()`: Try `import faiss`, on ImportError raise with message "FAISS is required for the faiss backend. Install with: pip install faiss-cpu"

- `add_documents()`:
  - Convert embeddings to `np.array(embeddings, dtype=np.float32)`, then call `faiss.normalize_L2(vectors)` (in-place on the copy, not on caller's data).
  - Create collection dict on first add (dimension from vectors.shape[1]).
  - For upsert semantics: check if each str_id already in `id_to_int`; if so, remove old vector via `index.remove_ids(np.array([old_int_id]))` before adding new one.
  - Assign sequential integer IDs via `next_int_id` counter.
  - Use `index.add_with_ids(vectors, np.array(int_ids, dtype=np.int64))` for explicit ID assignment with IndexIDMap.
  - Store documents and metadatas in companion dicts keyed by int_id.

- `search()`:
  - Validate collection exists (raise `ValueError` if not, matching BaseVectorBackend contract).
  - Guard for empty index: `if coll["index"].ntotal == 0: return {"ids": [[]], "distances": [[]], "documents": [[]], "metadatas": [[]]}`.
  - Clamp n_results: `n_results = min(n_results, coll["index"].ntotal)`.
  - Convert query to `np.array([query_embedding], dtype=np.float32)`, then `faiss.normalize_L2(query)`.
  - Call `distances, indices = coll["index"].search(query, n_results)`.
  - Convert squared L2 distances to cosine distances: `cosine_distances = (distances[0] / 2.0).tolist()`. This is correct because for L2-normalized vectors: squared_L2 = 2 * (1 - cos_sim) = 2 * cosine_distance.
  - Map integer indices back to string IDs, documents, metadatas.
  - Return column-oriented dict matching ChromaDB format: `{"ids": [result_ids], "distances": [cosine_distances], "documents": [result_docs], "metadatas": [result_metas]}`.

- `delete()`:
  - Validate collection exists (raise `ValueError` if not).
  - For each string ID: look up int_id, call `index.remove_ids(np.array([int_id]))`, remove from all mapping dicts.
  - Silently skip IDs that don't exist (per BaseVectorBackend contract).

- `count()`:
  - Validate collection exists (raise `ValueError` if not).
  - Return `coll["index"].ntotal`.

- `collection_exists()`: Override with simple `collection_name in self._collections` (more efficient than base class try/except).

**2. `lobster/core/vector/backends/pgvector_backend.py`** — PgVectorBackend stub:

- Class-level `_MSG` constant: "pgvector backend is planned for v2.0. Use LOBSTER_VECTOR_BACKEND=chromadb (default) or LOBSTER_VECTOR_BACKEND=faiss for current backends."
- All 4 abstract methods (`add_documents`, `search`, `delete`, `count`) raise `NotImplementedError(self._MSG)`.
- No external imports needed beyond BaseVectorBackend.
- Brief docstring explaining this is a future placeholder.

**3. Update `lobster/core/vector/config.py`** — Extend `create_backend()`:

- Add two `if` branches after the existing chromadb branch (before the final raise):
  ```
  if self.backend == SearchBackend.faiss:
      from lobster.core.vector.backends.faiss_backend import FAISSBackend
      return FAISSBackend()

  if self.backend == SearchBackend.pgvector:
      from lobster.core.vector.backends.pgvector_backend import PgVectorBackend
      return PgVectorBackend()
  ```
- Update the final `raise ValueError` message to: `f"Unsupported backend: {self.backend}. Available: chromadb, faiss, pgvector"`

IMPORTANT: Do NOT edit `lobster/core/vector/backends/__init__.py` -- keep it minimal per existing convention. The lazy import in config.py is sufficient.
  </action>
  <verify>
Run: `python -c "from lobster.core.vector.backends.faiss_backend import FAISSBackend; print('FAISSBackend importable')"` (will fail if faiss not installed, but module itself should parse).
Run: `python -c "from lobster.core.vector.backends.pgvector_backend import PgVectorBackend; b = PgVectorBackend(); print('PgVectorBackend created')"` (should succeed, no external deps).
Run: `python -c "from lobster.core.vector.config import VectorSearchConfig; from lobster.core.schemas.search import SearchBackend; c = VectorSearchConfig(backend=SearchBackend.pgvector); b = c.create_backend(); print(type(b))"` (should print PgVectorBackend).
  </verify>
  <done>
FAISSBackend class implements all 4 BaseVectorBackend abstract methods with IndexIDMap, L2 normalization, string-to-int ID mapping, and squared-L2-to-cosine distance conversion. PgVectorBackend stub raises NotImplementedError with helpful v2.0 message on all methods. VectorSearchConfig.create_backend() routes faiss and pgvector backends correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for all backends and updated config factory tests</name>
  <files>
    tests/unit/core/vector/test_backends.py
    tests/unit/core/vector/test_config.py
  </files>
  <action>
**1. Create `tests/unit/core/vector/test_backends.py`** — Comprehensive backend unit tests:

Use the `sys.modules` patching pattern established in `test_embedders.py` and `test_rerankers.py` for mocking FAISS. Do NOT require faiss-cpu to be installed for tests to run.

**TestFAISSBackend class** — Test with mocked faiss module:

Helper `_make_backend_and_mocks()`:
- Create `mock_faiss = MagicMock()`.
- Create a real-ish mock index: `mock_index = MagicMock()`, set `mock_index.ntotal = 0`, `mock_index.search = MagicMock()`, `mock_index.add_with_ids = MagicMock()`, `mock_index.remove_ids = MagicMock()`.
- `mock_id_map = MagicMock(wraps=mock_index)` for the IndexIDMap wrapper.
- `mock_faiss.IndexFlatL2.return_value = mock_index`.
- `mock_faiss.IndexIDMap.return_value = mock_id_map`.
- `mock_faiss.normalize_L2 = MagicMock()` (no-op in tests, normalization verified separately).
- Use `patch.dict("sys.modules", {"faiss": mock_faiss})` to inject mock, then import FAISSBackend inside the patch context.
- Return `(backend, mock_faiss, mock_index, mock_id_map)`.

Test cases (each imports FAISSBackend inside sys.modules patch):
- `test_add_documents_creates_collection`: Add 2 docs to new collection. Assert `mock_faiss.IndexFlatL2` called with correct dimension. Assert `mock_faiss.IndexIDMap` wraps the IndexFlatL2. Assert `add_with_ids` called with numpy array. Assert `normalize_L2` called on the vectors.
- `test_add_documents_stores_documents_and_metadatas`: Add docs with documents=["a","b"] and metadatas=[{"k":"v1"},{"k":"v2"}]. Assert internal dicts populated correctly by checking `backend._collections[name]["documents"]` and `backend._collections[name]["metadatas"]`.
- `test_search_empty_index_returns_empty`: Create collection then search with ntotal=0. Assert returns `{"ids": [[]], "distances": [[]], "documents": [[]], "metadatas": [[]]}`.
- `test_search_nonexistent_collection_raises_valueerror`: Search collection that was never created. Assert `pytest.raises(ValueError, match="does not exist")`.
- `test_search_converts_squared_l2_to_cosine_distance`: Mock index.search to return `(np.array([[0.4, 1.0]]), np.array([[0, 1]]))`. Set up collection with 2 docs. Assert returned distances are `[0.2, 0.5]` (divided by 2.0). This is the critical distance conversion test.
- `test_search_normalizes_query_vector`: Call search, assert `mock_faiss.normalize_L2` was called on the query array.
- `test_search_clamps_n_results_to_available`: Set ntotal=3, request n_results=10. Assert `index.search` called with k=3.
- `test_delete_removes_from_mappings`: Add doc, then delete it. Assert int_to_id and id_to_int no longer contain the entry. Assert `index.remove_ids` called.
- `test_delete_nonexistent_collection_raises_valueerror`: Delete from non-existent collection. Assert `pytest.raises(ValueError)`.
- `test_delete_nonexistent_id_silently_ignored`: Add doc "a", delete doc "b" (doesn't exist). No error raised.
- `test_count_returns_ntotal`: Set mock_index.ntotal=42. Assert `backend.count(name) == 42`.
- `test_count_nonexistent_collection_raises_valueerror`: Count on non-existent collection. Assert `pytest.raises(ValueError)`.
- `test_collection_exists_true_and_false`: Add to "col_a". Assert `collection_exists("col_a") is True`. Assert `collection_exists("col_b") is False`.
- `test_upsert_overwrites_existing_id`: Add doc with id="A", then add again with same id="A" but different embedding. Assert `remove_ids` was called for old int_id before new add_with_ids.
- `test_import_error_has_helpful_message`: Create FAISSBackend, then patch sys.modules to make faiss import fail. Call add_documents. Assert `pytest.raises(ImportError, match="pip install faiss-cpu")`.

**TestPgVectorBackend class** — Simple stub tests:
- `test_add_documents_raises_not_implemented`: Assert `pytest.raises(NotImplementedError, match="v2.0")`.
- `test_search_raises_not_implemented`: Assert `pytest.raises(NotImplementedError, match="v2.0")`.
- `test_delete_raises_not_implemented`: Assert `pytest.raises(NotImplementedError, match="v2.0")`.
- `test_count_raises_not_implemented`: Assert `pytest.raises(NotImplementedError, match="v2.0")`.
- `test_is_base_vector_backend_subclass`: Assert `isinstance(PgVectorBackend(), BaseVectorBackend)`.
- `test_error_message_suggests_alternatives`: Assert "chromadb" and "faiss" appear in the error message.

**TestBaseVectorBackendContract class** — Verify ABC enforcement:
- `test_abc_cannot_be_instantiated`: Assert `pytest.raises(TypeError)` on `BaseVectorBackend()`.
- `test_faiss_is_valid_subclass`: Assert FAISSBackend instance `isinstance(..., BaseVectorBackend)`.
- `test_pgvector_is_valid_subclass`: Assert PgVectorBackend instance `isinstance(..., BaseVectorBackend)`.

**2. Update `tests/unit/core/vector/test_config.py`** — Modify existing factory tests:

- **Replace** `test_create_backend_unsupported` (line 82-86): This test currently asserts `SearchBackend.faiss` raises ValueError. Change it to `test_create_backend_faiss` that asserts `create_backend()` returns a FAISSBackend instance. Use the same lazy-import-skip pattern as the chromadb test:
  ```python
  def test_create_backend_faiss(self):
      """create_backend() with faiss returns FAISSBackend."""
      try:
          import faiss
      except ImportError:
          pytest.skip("faiss-cpu not installed")
      config = VectorSearchConfig(backend=SearchBackend.faiss)
      backend = config.create_backend()
      from lobster.core.vector.backends.faiss_backend import FAISSBackend
      assert isinstance(backend, FAISSBackend)
  ```

- **Add** `test_create_backend_pgvector`: Assert pgvector config creates PgVectorBackend (no skip needed, no external deps):
  ```python
  def test_create_backend_pgvector(self):
      """create_backend() with pgvector returns PgVectorBackend."""
      config = VectorSearchConfig(backend=SearchBackend.pgvector)
      backend = config.create_backend()
      from lobster.core.vector.backends.pgvector_backend import PgVectorBackend
      assert isinstance(backend, PgVectorBackend)
  ```

- **Add** `test_create_backend_error_message_updated`: Verify the ValueError message now lists all 3 backends. Since all 3 enum values are now handled, this tests the else branch won't be hit for valid values. Can be a simple assertion that the error message in the source mentions "chromadb, faiss, pgvector".
  </action>
  <verify>
Run: `cd /Users/tyo/Omics-OS/lobster && python -m pytest tests/unit/core/vector/test_backends.py -v` (all tests should pass).
Run: `cd /Users/tyo/Omics-OS/lobster && python -m pytest tests/unit/core/vector/test_config.py -v` (all tests should pass, including updated factory tests).
Run: `cd /Users/tyo/Omics-OS/lobster && python -m pytest tests/unit/core/vector/ -v` (full vector test suite -- all existing tests must still pass).
  </verify>
  <done>
test_backends.py has ~20 tests covering FAISS backend (mocked faiss, distance conversion, ID mapping, upsert, delete, empty index, error messages), pgvector stub (NotImplementedError on all methods, helpful messages), and ABC contract. test_config.py updated: old test_create_backend_unsupported replaced with test_create_backend_faiss, new test_create_backend_pgvector added. All existing vector tests pass unchanged.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/unit/core/vector/ -v` -- All vector unit tests pass (existing + new).
2. `python -c "from lobster.core.vector.config import VectorSearchConfig; from lobster.core.schemas.search import SearchBackend; c = VectorSearchConfig(backend=SearchBackend.pgvector); b = c.create_backend(); print(type(b).__name__)"` -- Prints "PgVectorBackend".
3. `python -c "from lobster.core.vector.backends.pgvector_backend import PgVectorBackend; b = PgVectorBackend(); b.search('x', [0.1])"` -- Raises NotImplementedError with "v2.0" message.
4. Grep confirms no changes to `lobster/core/vector/service.py` (service layer untouched).
5. Grep confirms `lobster/core/vector/backends/faiss_backend.py` contains `faiss.normalize_L2` call (L2 normalization).
6. Grep confirms `lobster/core/vector/backends/faiss_backend.py` contains `/ 2.0` (distance conversion).
</verification>

<success_criteria>
- INFRA-05: FAISSBackend implements BaseVectorBackend with IndexIDMap(IndexFlatL2), L2 normalization, string-to-int ID mapping, and squared-L2-to-cosine distance conversion
- INFRA-06: PgVectorBackend stub raises NotImplementedError with "v2.0" guidance on all 4 abstract methods
- INFRA-07: VectorSearchConfig.create_backend() routes faiss/pgvector backends; LOBSTER_VECTOR_BACKEND env var already parsed by from_env()
- TEST-01: Unit tests for all 3 backends with mocked dependencies; ~20 new tests in test_backends.py + 2 updated/added in test_config.py
- All existing tests pass unchanged (service layer untouched by backend changes)
</success_criteria>

<output>
After completion, create `.planning/phases/05-scalability/05-01-SUMMARY.md`
</output>
